====================================================================================================
SANITY CHECK SUMMARY ACROSS ALL SEEDS - ResNet50 vs ResNet50-ImageNet (Pretrained)
====================================================================================================

TABLE 1: LAYER-WISE RELEVANCE RANDOMIZATION - Mean Degradation (higher = better)
----------------------------------------------------------------------------------------------------
Model              Method                      seed_14      seed_51      seed_92         Mean±Std
----------------------------------------------------------------------------------------------------
ResNet50           Saliency                     0.8265       0.8531       0.9035     0.8610±0.0319
ResNet50           IntegratedGradients          0.6883       0.7379       0.7124     0.7129±0.0203
ResNet50           GradientShap                 0.8043       0.8954       0.8447     0.8481±0.0373
ResNet50           GradCAM                      0.6563       0.6243       0.7370     0.6725±0.0474
ResNet50           FeaturePermutation           0.8893       0.8492       0.7952     0.8446±0.0386

ResNet50-ImageNet  Saliency                     0.9983       0.9976       0.9981     0.9980±0.0003
ResNet50-ImageNet  IntegratedGradients          0.9920       0.9954       0.9956     0.9943±0.0016
ResNet50-ImageNet  GradientShap                 0.9960       0.9963       0.9977     0.9967±0.0007
ResNet50-ImageNet  GradCAM                      0.9208       0.9685       0.9289     0.9394±0.0208
ResNet50-ImageNet  FeaturePermutation           0.9935       0.9841       0.9917     0.9898±0.0040

----------------------------------------------------------------------------------------------------

TABLE 2: INPUT RANDOMIZATION TEST - Mean Sensitivity (higher = better)
----------------------------------------------------------------------------------------------------
Model              Method                      seed_14      seed_51      seed_92         Mean±Std
----------------------------------------------------------------------------------------------------
ResNet50           Saliency                   0.002015     0.001475     0.003331     0.002274±0.000777
ResNet50           IntegratedGradients        0.000437     0.000465     0.000644     0.000515±0.000091
ResNet50           GradientShap               0.000686     0.000711     0.001057     0.000818±0.000168
ResNet50           GradCAM                    0.028925     0.028460     0.022729     0.026705±0.002813
ResNet50           FeaturePermutation         0.003893     0.002926     0.003741     0.003520±0.000419

ResNet50-ImageNet  Saliency                   0.081213     0.068500     0.085814     0.078509±0.007259
ResNet50-ImageNet  IntegratedGradients        0.025105     0.016249     0.019246     0.020200±0.003667
ResNet50-ImageNet  GradientShap               0.045173     0.026711     0.031316     0.034400±0.007858
ResNet50-ImageNet  GradCAM                    0.038752     0.023348     0.027692     0.029931±0.006455
ResNet50-ImageNet  FeaturePermutation         0.027132     0.028187     0.043819     0.033046±0.007631

----------------------------------------------------------------------------------------------------

TABLE 3: INPUT RANDOMIZATION - Cliff's Delta (effect size interpretation)
  Interpretation: |d|<0.147=Negligible, <0.33=Small, <0.474=Medium, >=0.474=Large
----------------------------------------------------------------------------------------------------
Model              Method                      seed_14      seed_51      seed_92       Mean       Interp
----------------------------------------------------------------------------------------------------
ResNet50           Saliency                    -0.2800      -0.3600      -0.2000    -0.2800        Small
ResNet50           IntegratedGradients          0.0400      -0.4400      -0.1200    -0.1733        Small
ResNet50           GradientShap                -0.6000      -0.2000       0.2800    -0.1733        Small
ResNet50           GradCAM                     -0.6000       0.2000      -0.2000    -0.2000        Small
ResNet50           FeaturePermutation           0.2000       0.3600       0.0400     0.2000        Small

ResNet50-ImageNet  Saliency                    -0.1200       0.4400       0.6000     0.3067        Small
ResNet50-ImageNet  IntegratedGradients          0.2800       0.1200       0.0400     0.1467   Negligible
ResNet50-ImageNet  GradientShap                -0.0400      -0.0400       0.5200     0.1467   Negligible
ResNet50-ImageNet  GradCAM                      0.5200      -0.1200       0.1200     0.1733        Small
ResNet50-ImageNet  FeaturePermutation          -0.0400      -0.0400      -0.1200    -0.0667   Negligible

----------------------------------------------------------------------------------------------------

====================================================================================================
COMPARISON: PRETRAINED (ImageNet) vs RANDOM INITIALIZATION
====================================================================================================

LAYER-WISE RANDOMIZATION IMPROVEMENT (ImageNet over Random Init):
----------------------------------------------------------------------------------------------------
Method                  ResNet50     ResNet50-ImageNet    Improvement (%)
----------------------------------------------------------------------------------------------------
Saliency                  0.8610            0.9980           +15.9%
IntegratedGradients       0.7129            0.9943           +39.5%
GradientShap              0.8481            0.9967           +17.5%
GradCAM                   0.6725            0.9394           +39.7%
FeaturePermutation        0.8446            0.9898           +17.2%
----------------------------------------------------------------------------------------------------
Average                   0.7878            0.9836           +24.9%
----------------------------------------------------------------------------------------------------

INPUT SENSITIVITY IMPROVEMENT (ImageNet over Random Init):
----------------------------------------------------------------------------------------------------
Method                  ResNet50     ResNet50-ImageNet    Improvement (x fold)
----------------------------------------------------------------------------------------------------
Saliency                0.002274          0.078509             34.5x
IntegratedGradients     0.000515          0.020200             39.2x
GradientShap            0.000818          0.034400             42.0x
GradCAM                 0.026705          0.029931              1.1x
FeaturePermutation      0.003520          0.033046              9.4x
----------------------------------------------------------------------------------------------------
Average                 0.006766          0.039217              5.8x (excluding GradCAM: ~31.5x)
----------------------------------------------------------------------------------------------------

====================================================================================================
SUMMARY INTERPRETATION
====================================================================================================

LAYER-WISE RANDOMIZATION:
  - ResNet50 (random init): Mean degradation = 0.79 (Good)
  - ResNet50-ImageNet (pretrained): Mean degradation = 0.98 (Excellent)
  - Pretrained model shows ~25% higher degradation, indicating explanations are 
    MORE sensitive to model weights when pretrained on ImageNet
  - This suggests pretrained features are more meaningful and better captured by XAI methods

INPUT RANDOMIZATION:
  - Pretrained model shows dramatically higher sensitivity to input perturbations
  - Saliency, IntegratedGradients, GradientShap show 30-40x higher sensitivity with pretraining
  - GradCAM shows similar sensitivity in both (already high due to spatial attention)
  - Higher sensitivity indicates explanations are more discriminative and input-dependent

CONCLUSION: 
  - Both models PASS sanity checks
  - ImageNet pretraining significantly improves explanation quality:
    1. Explanations are more faithful to model weights (layer randomization)
    2. Explanations are more sensitive to input changes (input randomization)
  - This supports using pretrained models for more interpretable XAI results

====================================================================================================
